{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/\n",
    "# Continued from 2.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "from scipy import stats as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(101, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the trained weights\n",
    "model.load_weights(\"weight.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    video_name\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi\n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi\n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi\n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"test/data/ucfTrainTestlist/testlist01.txt\", \"r\")\n",
    "temp = f.read()\n",
    "videos = temp.split('\\n')\n",
    "test = pd.DataFrame()\n",
    "test['video_name'] = videos\n",
    "test = test[:-1]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the tags\n",
    "train = pd.read_csv('train_new.csv')\n",
    "y = train['class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(path):\n",
    "    # removing all other files from the temp folder\n",
    "    files = glob('temp/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "def predict(indir, test, tmp=\"temp\"):\n",
    "    \n",
    "    # creating two lists to store predicted and actual tags\n",
    "    predict = []\n",
    "    actual = []\n",
    "\n",
    "    os.makedirs(tmp, exist_ok=True)\n",
    "    \n",
    "    # for loop to extract frames from each test video\n",
    "    for i in tqdm(range(test.shape[0])):\n",
    "        count = 0\n",
    "        \n",
    "        videoFile = test['video_name'][i]\n",
    "        inpath = os.path.join(indir, videoFile)\n",
    "        if not os.path.isfile(inpath):\n",
    "            raise Exception(\"Path does not exist {}\".format(inpath))\n",
    "            \n",
    "        clear(tmp)\n",
    "        cap = cv2.VideoCapture(inpath)   # capturing the video from the given path\n",
    "        try:\n",
    "            frameRate = cap.get(5) #frame rate\n",
    "            x=1\n",
    "  \n",
    "            while(cap.isOpened()):\n",
    "                frameId = cap.get(1) #current frame number\n",
    "                ret, frame = cap.read()\n",
    "                if (ret != True):\n",
    "                    break\n",
    "                if (frameId % math.floor(frameRate) == 0):\n",
    "                    # storing the frames of this particular video in temp folder\n",
    "                    filename ='temp/' + \"_frame%d.jpg\" % count;count+=1\n",
    "                    cv2.imwrite(filename, frame)\n",
    "        finally:\n",
    "            cap.release()\n",
    "\n",
    "        # reading all the frames from temp folder\n",
    "        images = glob(\"temp/*.jpg\")\n",
    "\n",
    "        prediction_images = []\n",
    "        for i in range(len(images)):\n",
    "            img = image.load_img(images[i], target_size=(224,224,3))\n",
    "            img = image.img_to_array(img)\n",
    "            img = img/255\n",
    "            prediction_images.append(img)\n",
    "\n",
    "        # converting all the frames for a test video into numpy array\n",
    "        prediction_images = np.array(prediction_images)\n",
    "        # extracting features using pre-trained model\n",
    "        prediction_images = base_model.predict(prediction_images)\n",
    "        \n",
    "        # converting features in one dimensional array\n",
    "        prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
    "        # predicting tags for each array\n",
    "        prediction = model.predict_classes(prediction_images)\n",
    "        \n",
    "        # appending the mode of predictions in predict list to assign the tag to the video\n",
    "        predict.append(y.columns.values[s.mode(prediction)[0][0]])\n",
    "        # appending the actual tag of the video\n",
    "        actual.append(videoFile.split('/')[1].split('_')[1])\n",
    "        \n",
    "    return predict, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3783/3783 [52:19<00:00,  1.21it/s]  \n"
     ]
    }
   ],
   "source": [
    "pred, actual = predict(\"test/data/UCF-101\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.20592122653979"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the accuracy of the predicted tags\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(pred, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
