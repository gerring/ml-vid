{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(pardir='test/data/sports/data', sort=True):\n",
    "    \n",
    "    from os.path import isdir, basename, join, isfile\n",
    "    files = [f for f in os.listdir(pardir) if isdir(join(pardir, f))]\n",
    "\n",
    "    train_image = []\n",
    "    train_class = []\n",
    "\n",
    "    for idir in files:\n",
    "        clazz = basename(idir)\n",
    "        if clazz.startswith(\".\"):\n",
    "            continue\n",
    "        \n",
    "        images = os.listdir(pardir+\"/\"+clazz)\n",
    "        for i in tqdm(range(len(images))):\n",
    "            \n",
    "            image_name = images[i] \n",
    "            lc = image_name.lower()\n",
    "            if not lc.endswith(\".jpg\") and not lc.endswith(\".jpeg\") and not lc.endswith(\".png\"):\n",
    "                continue\n",
    "            \n",
    "            if isdir(join(pardir, clazz, image_name)):\n",
    "                continue\n",
    "                \n",
    "            if lc.endswith(\".ipynb_checkpoints\"):\n",
    "                continue\n",
    "            \n",
    "            train_image.append(clazz+\"/\"+image_name)\n",
    "            train_class.append(clazz)\n",
    "        \n",
    "    train_data = pd.DataFrame()\n",
    "    train_data['image'] = train_image\n",
    "    train_data['class'] = train_class\n",
    "\n",
    "    if sort:\n",
    "        train_data = train_data.sort_values(by=['class'])\n",
    "        \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 719/719 [00:00<00:00, 29992.09it/s]\n",
      "100%|██████████| 611/611 [00:00<00:00, 29482.64it/s]\n",
      "100%|██████████| 799/799 [00:00<00:00, 30027.50it/s]\n",
      "100%|██████████| 715/715 [00:00<00:00, 28430.43it/s]\n",
      "100%|██████████| 746/746 [00:00<00:00, 29335.47it/s]\n",
      "100%|██████████| 715/715 [00:00<00:00, 29563.56it/s]\n",
      "100%|██████████| 671/671 [00:00<00:00, 26046.03it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 3366.67it/s]\n",
      "100%|██████████| 495/495 [00:00<00:00, 25486.49it/s]\n",
      "100%|██████████| 713/713 [00:00<00:00, 26274.97it/s]\n",
      "100%|██████████| 713/713 [00:00<00:00, 28894.37it/s]\n",
      "100%|██████████| 679/679 [00:00<00:00, 25075.79it/s]\n",
      "100%|██████████| 635/635 [00:00<00:00, 26674.91it/s]\n",
      "100%|██████████| 572/572 [00:00<00:00, 26646.77it/s]\n",
      "100%|██████████| 689/689 [00:00<00:00, 43723.72it/s]\n",
      "100%|██████████| 481/481 [00:00<00:00, 49900.08it/s]\n",
      "100%|██████████| 718/718 [00:00<00:00, 53538.91it/s]\n",
      "100%|██████████| 938/938 [00:00<00:00, 23526.45it/s]\n",
      "100%|██████████| 705/705 [00:00<00:00, 28406.59it/s]\n",
      "100%|██████████| 577/577 [00:00<00:00, 26234.29it/s]\n",
      "100%|██████████| 455/455 [00:00<00:00, 26866.12it/s]\n",
      "100%|██████████| 687/687 [00:00<00:00, 27474.39it/s]\n",
      "100%|██████████| 536/536 [00:00<00:00, 19899.68it/s]\n"
     ]
    }
   ],
   "source": [
    "train = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_and_labels(pdir='test/data/sports/data', train=train):\n",
    "    \n",
    "    # creating an empty list\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # for loop to read and store frames\n",
    "    for i in tqdm(range(train.shape[0])):\n",
    "        # loading the image and keeping the target size as (500,300,3)\n",
    "        # The images are variable size\n",
    "        impath = pdir+'/'+train['image'][i]\n",
    "        if i % 1000 == 0:\n",
    "            print(impath)\n",
    "        try:\n",
    "            image = cv2.imread(impath)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            \n",
    "            # appending the image to the train_image list\n",
    "            images.append(image)\n",
    "            labels.append(train['class'][i])\n",
    "        except:\n",
    "            raise Exception(\"Problem with {}\".format(impath))\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/14360 [00:00<04:23, 54.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/gymnastics/00000372.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1012/14360 [00:11<02:39, 83.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/wrestling/00000292.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2004/14360 [00:25<03:15, 63.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/football/00000023.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 3015/14360 [00:37<02:31, 74.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/baseball/00000307.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 4003/14360 [00:48<01:46, 97.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/ice_hockey/00000678.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 5011/14360 [01:01<02:46, 56.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/basketball/00000110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 6012/14360 [01:12<01:52, 74.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/table_tennis/00000585.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 7016/14360 [01:25<01:24, 86.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/motogp/00000511.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 8012/14360 [01:37<01:06, 95.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/fencing/00000022.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 9013/14360 [01:49<00:55, 96.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/swimming/00000535.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 10019/14360 [02:01<00:44, 97.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/tennis/00000266.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 11014/14360 [02:13<00:54, 61.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/badminton/00000333.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 12016/14360 [02:24<00:27, 85.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/boxing/00000146.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 13018/14360 [02:31<00:07, 173.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/kabaddi/00000445.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 14030/14360 [02:36<00:01, 208.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/data/sports/data/shooting/00000071.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14360/14360 [02:38<00:00, 90.70it/s] \n"
     ]
    }
   ],
   "source": [
    "data, labels = images_and_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.25, stratify=labels, random_state=42)\n",
    "\n",
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trotation_range=30,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator()\n",
    "\n",
    "# define the ImageNet mean subtraction (in RGB order) and set the\n",
    "# the mean subtraction value for each of the data augmentation\n",
    "# objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 22s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the ResNet-50 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "def compile(epochs=50, model=model) :\n",
    "    # compile our model (this needs to be done after our setting our\n",
    "    # layers to being non-trainable)\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    opt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / epochs)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/25\n",
      "336/336 [==============================] - 48047s 143s/step - loss: 2.1506 - accuracy: 0.3833 - val_loss: 1.6808 - val_accuracy: 0.5633\n",
      "Epoch 2/25\n",
      "336/336 [==============================] - 397s 1s/step - loss: 1.9826 - accuracy: 0.4288 - val_loss: 1.5129 - val_accuracy: 0.6035\n",
      "Epoch 3/25\n",
      "336/336 [==============================] - 397s 1s/step - loss: 1.8437 - accuracy: 0.4683 - val_loss: 1.3966 - val_accuracy: 0.6250\n",
      "Epoch 4/25\n",
      "336/336 [==============================] - 430s 1s/step - loss: 1.7410 - accuracy: 0.4990 - val_loss: 1.2971 - val_accuracy: 0.6532\n",
      "Epoch 5/25\n",
      "336/336 [==============================] - 447s 1s/step - loss: 1.6566 - accuracy: 0.5232 - val_loss: 1.2279 - val_accuracy: 0.6618\n",
      "Epoch 6/25\n",
      "336/336 [==============================] - 418s 1s/step - loss: 1.5986 - accuracy: 0.5311 - val_loss: 1.1704 - val_accuracy: 0.6766\n",
      "Epoch 7/25\n",
      "336/336 [==============================] - 430s 1s/step - loss: 1.5340 - accuracy: 0.5490 - val_loss: 1.1162 - val_accuracy: 0.6936\n",
      "Epoch 8/25\n",
      "336/336 [==============================] - 462s 1s/step - loss: 1.4860 - accuracy: 0.5670 - val_loss: 1.0765 - val_accuracy: 0.6995\n",
      "Epoch 9/25\n",
      "336/336 [==============================] - 448s 1s/step - loss: 1.4341 - accuracy: 0.5763 - val_loss: 1.0428 - val_accuracy: 0.7059\n",
      "Epoch 10/25\n",
      "336/336 [==============================] - 446s 1s/step - loss: 1.4074 - accuracy: 0.5766 - val_loss: 1.0090 - val_accuracy: 0.7168\n",
      "Epoch 11/25\n",
      "336/336 [==============================] - 472s 1s/step - loss: 1.3506 - accuracy: 0.6023 - val_loss: 0.9841 - val_accuracy: 0.7227\n",
      "Epoch 12/25\n",
      "336/336 [==============================] - 488s 1s/step - loss: 1.3353 - accuracy: 0.6054 - val_loss: 0.9620 - val_accuracy: 0.7296\n",
      "Epoch 13/25\n",
      "336/336 [==============================] - 471s 1s/step - loss: 1.2991 - accuracy: 0.6113 - val_loss: 0.9411 - val_accuracy: 0.7363\n",
      "Epoch 14/25\n",
      "336/336 [==============================] - 1295s 4s/step - loss: 1.2752 - accuracy: 0.6217 - val_loss: 0.9189 - val_accuracy: 0.7422\n",
      "Epoch 15/25\n",
      "336/336 [==============================] - 410s 1s/step - loss: 1.2494 - accuracy: 0.6304 - val_loss: 0.9120 - val_accuracy: 0.7419\n",
      "Epoch 16/25\n",
      "336/336 [==============================] - 455s 1s/step - loss: 1.2125 - accuracy: 0.6327 - val_loss: 0.8855 - val_accuracy: 0.7489\n",
      "Epoch 17/25\n",
      "336/336 [==============================] - 476s 1s/step - loss: 1.2016 - accuracy: 0.6451 - val_loss: 0.8746 - val_accuracy: 0.7536\n",
      "Epoch 18/25\n",
      "336/336 [==============================] - 483s 1s/step - loss: 1.2034 - accuracy: 0.6427 - val_loss: 0.8618 - val_accuracy: 0.7564\n",
      "Epoch 19/25\n",
      "336/336 [==============================] - 1986s 6s/step - loss: 1.1697 - accuracy: 0.6498 - val_loss: 0.8530 - val_accuracy: 0.7553\n",
      "Epoch 20/25\n",
      "336/336 [==============================] - 448s 1s/step - loss: 1.1424 - accuracy: 0.6647 - val_loss: 0.8372 - val_accuracy: 0.7595\n",
      "Epoch 21/25\n",
      "336/336 [==============================] - 507s 2s/step - loss: 1.1435 - accuracy: 0.6597 - val_loss: 0.8323 - val_accuracy: 0.7628\n",
      "Epoch 22/25\n",
      "336/336 [==============================] - 564s 2s/step - loss: 1.1230 - accuracy: 0.6668 - val_loss: 0.8219 - val_accuracy: 0.7659\n",
      "Epoch 23/25\n",
      "336/336 [==============================] - 1708s 5s/step - loss: 1.1035 - accuracy: 0.6695 - val_loss: 0.8083 - val_accuracy: 0.7687\n",
      "Epoch 24/25\n",
      "336/336 [==============================] - 2879s 9s/step - loss: 1.0959 - accuracy: 0.6733 - val_loss: 0.8002 - val_accuracy: 0.7718\n",
      "Epoch 25/25\n",
      "336/336 [==============================] - 470s 1s/step - loss: 1.0849 - accuracy: 0.6725 - val_loss: 0.7942 - val_accuracy: 0.7715\n"
     ]
    }
   ],
   "source": [
    "def train(epochs=25, model=model):\n",
    "    print(\"[INFO] training head...\")\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    mcp_save = ModelCheckpoint('sports_weight.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "    H = model.fit(\n",
    "        x=trainAug.flow(trainX, trainY, batch_size=32),\n",
    "        steps_per_epoch=len(trainX) // 32,\n",
    "        validation_data=valAug.flow(testX, testY),\n",
    "        validation_steps=len(testX) // 32,\n",
    "        epochs=epochs,\n",
    "        callbacks=[mcp_save])\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     badminton       0.74      0.73      0.73       232\n",
      "      baseball       0.72      0.75      0.74       183\n",
      "    basketball       0.69      0.70      0.70       122\n",
      "        boxing       0.72      0.74      0.73       176\n",
      "         chess       0.84      0.80      0.82       119\n",
      "       cricket       0.79      0.73      0.76       166\n",
      "       fencing       0.71      0.77      0.74       156\n",
      "      football       0.76      0.88      0.81       196\n",
      "      formula1       0.84      0.84      0.84       169\n",
      "    gymnastics       0.83      0.67      0.74       178\n",
      "        hockey       0.76      0.55      0.64       142\n",
      "    ice_hockey       0.85      0.94      0.89       177\n",
      "       kabaddi       0.63      0.80      0.70       113\n",
      "        motogp       0.97      0.84      0.90       167\n",
      "      shooting       0.87      0.77      0.82       133\n",
      "      swimming       0.94      0.95      0.95       171\n",
      "  table_tennis       0.80      0.74      0.77       176\n",
      "        tennis       0.72      0.80      0.76       178\n",
      "    volleyball       0.76      0.82      0.79       176\n",
      "weight_lifting       0.77      0.69      0.73       143\n",
      "     wrestling       0.65      0.71      0.68       150\n",
      "           wwe       0.66      0.68      0.67       167\n",
      "\n",
      "      accuracy                           0.77      3590\n",
      "     macro avg       0.77      0.77      0.77      3590\n",
      "  weighted avg       0.78      0.77      0.77      3590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x=testX.astype(\"float32\"), batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"sports_model.h5\", save_format=\"h5\")\n",
    "\n",
    "# serialize the label binarizer to disk\n",
    "f = open(\"sports_labels.pkl\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
